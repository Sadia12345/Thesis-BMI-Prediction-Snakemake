\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{geometry}

\geometry{margin=2.5cm}

\title{Machine Learning Prediction of BMI from Human Gut Microbiome:\\ Scaling Limitations and Optimization Strategies}
\author{Sadia Zaman}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
The gut microbiome consists of trillions of microorganisms that influence host metabolism and health. Recent studies suggest a link between microbiome composition and Body Mass Index (BMI). However, processing high-dimensional metagenomic data presents significant computational challenges. This thesis investigates the predictive power of gut microbiome features for BMI using machine learning models (GLMNet, Random Forest) on a large-scale cohort (Metalog, n=18,024). We specifically examine the scaling limitations of these models and evaluate the trade-off between sample size, feature dimensionality, and predictive accuracy. Our results demonstrate that feature filtering (removing rare species) reduces memory usage by 75\% without compromising model performance, enabling locally feasible analysis of large datasets.
\end{abstract}

\section{Introduction}
Obesity is a global health crisis... [Write about BMI and Microbiome background here].
Computionally, analyzing microbiome data is difficult due to high dimensionality (thousands of species) and data sparsity (many zeros).

\section{Methods}

\subsection{Data Cohort}
We utilized the Metalog dataset, comprising 18,024 human stool samples with deeply sequenced metagenomes.
\begin{itemize}
    \item \textbf{Inclusion Criteria:} Samples with valid BMI, Age, and Sex metadata.
    \item \textbf{Exclusion Criteria:} Weight and Height were excluded to prevent data leakage (since $BMI = Weight / Height^2$).
\end{itemize}

\subsection{Preprocessing}
To address computational bottlenecks, we implemented a prevalence filtering strategy:
\begin{itemize}
    \item \textbf{Original Feature Space:} ~6,300 species.
    \item \textbf{Filtered Feature Space:} ~1,500 species (Retaining only those present in $>1\%$ of samples).
\end{itemize}

\subsection{Machine Learning Pipeline}
We utilized the \texttt{mikropml} package within a reproducible Snakemake workflow.
Models trained:
\begin{itemize}
    \item \textbf{GLMNet (Lasso/Elastic Net):} Linear baseline.
    \item \textbf{Random Forest:} Non-linear ensemble method.
\end{itemize}

\subsection{Scaling \& Saturation Study}
To determine the optimal sample size, we performed a saturation analysis by training models on subsets of varying sizes ($n=1,000, 2,000, 5,000, 10,000, 13,000, 15,000$) and observing the plateau in predictive performance (RMSE).

\section{Results}

\subsection{Computational Efficiency}
(We will add a table here comparing RAM usage before/after filtering).

\subsection{Prediction Performance}
(We will add the Plot of AUROC vs Sample Size here).
Preliminary results indicate that prefiltering allows for robust training on standard hardware.

\section{Discussion}
Our findings suggest that while large datasets offer statistical power, the majority of microbiome features are rare and do not contribute significantly to BMI prediction...

\bibliographystyle{plain}
% \bibliography{references}

\end{document}
